{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dfcf7ea",
   "metadata": {},
   "source": [
    "Code in order to transform our dataset from grayscale images of peoples faces into feature maps which we will train a classifier on. Only needs to be run once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93a6359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8cc62bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "# Indices from the mediapipe_landmarks_detection gist and common docs\n",
    "FACE_LEFT_CHEEK = 234\n",
    "FACE_RIGHT_CHEEK = 454\n",
    "\n",
    "MOUTH_LEFT = 61\n",
    "MOUTH_RIGHT = 291\n",
    "MOUTH_TOP_INNER = 13\n",
    "MOUTH_BOTTOM_INNER = 14\n",
    "NOSE_TIP = 1\n",
    "\n",
    "# Eyes\n",
    "RIGHT_EYE_OUTER = 33\n",
    "RIGHT_EYE_INNER = 133\n",
    "RIGHT_EYE_TOP = 159\n",
    "RIGHT_EYE_BOTTOM = 145\n",
    "\n",
    "LEFT_EYE_OUTER = 263\n",
    "LEFT_EYE_INNER = 362\n",
    "LEFT_EYE_TOP = 386\n",
    "LEFT_EYE_BOTTOM = 374\n",
    "\n",
    "# Eyebrow groups from the gist you saw\n",
    "LEFT_EYE_INDICES = [362, 382, 381, 380, 374, 373, 390, 249, 263, 466,\n",
    "                    388, 387, 386, 385, 384, 398]\n",
    "RIGHT_EYE_INDICES = [33, 7, 163, 144, 145, 153, 154, 155, 133, 173,\n",
    "                     157, 158, 159, 160, 161, 246]\n",
    "\n",
    "LEFT_EYEBROW_INDICES = [336, 296, 334, 293, 300, 276, 283, 282, 295, 285]\n",
    "RIGHT_EYEBROW_INDICES = [70, 63, 105, 66, 107, 55, 65, 52, 53, 46]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f686d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_feature_array(feature_dict):\n",
    "    \"\"\"\n",
    "    Takes a dict {name: value} and returns:\n",
    "      - values as np.float32 array\n",
    "      - list of names in matching order\n",
    "    \"\"\"\n",
    "    names = list(feature_dict.keys())\n",
    "    values = np.array(list(feature_dict.values()), dtype=np.float32)\n",
    "    return values, names\n",
    "\n",
    "\n",
    "def _dist(p1, p2):\n",
    "    return np.linalg.norm(p1 - p2)\n",
    "\n",
    "\n",
    "def _slope(p_from, p_to):\n",
    "    dx = p_to[0] - p_from[0]\n",
    "    dy = p_to[1] - p_from[1]\n",
    "    return dy / (dx + 1e-6)\n",
    "\n",
    "\n",
    "def _signed_point_line_distance_2d(p, a, b):\n",
    "    \"\"\"\n",
    "    Signed distance from point p to the line through a and b in xy.\n",
    "    Uses 2D cross product for sign.\n",
    "    \"\"\"\n",
    "    p2 = p[:2]\n",
    "    a2 = a[:2]\n",
    "    b2 = b[:2]\n",
    "    v = b2 - a2\n",
    "    w = p2 - a2\n",
    "    cross = v[0] * w[1] - v[1] * w[0]\n",
    "    denom = np.linalg.norm(v) + 1e-6\n",
    "    return cross / denom\n",
    "\n",
    "\n",
    "def _get_inner_outer_brow_points(pts, indices, side):\n",
    "    \"\"\"\n",
    "    side: 'left' or 'right' from subject perspective.\n",
    "    Uses x coordinate to choose inner vs outer point.\n",
    "    \"\"\"\n",
    "    brow_pts = pts[indices]          # shape (N, 3)\n",
    "    xs = brow_pts[:, 0]\n",
    "\n",
    "    if side == \"left\":\n",
    "        # Subject left brow is on viewer right\n",
    "        # inner is closer to center (smaller x), outer larger x\n",
    "        inner_local = int(xs.argmin())\n",
    "        outer_local = int(xs.argmax())\n",
    "    else:\n",
    "        # Subject right brow is on viewer left\n",
    "        # inner is closer to center (larger x), outer smaller x\n",
    "        inner_local = int(xs.argmax())\n",
    "        outer_local = int(xs.argmin())\n",
    "\n",
    "    inner_pt = brow_pts[inner_local]\n",
    "    outer_pt = brow_pts[outer_local]\n",
    "    return inner_pt, outer_pt\n",
    "\n",
    "\n",
    "def extract_features(landmarks):\n",
    "    \"\"\"\n",
    "    landmarks: list of 468 mediapipe landmarks (with .x, .y, .z)\n",
    "    Returns:\n",
    "        features: 1D np.array of floats\n",
    "        feature_names: list of strings in matching order\n",
    "    \"\"\"\n",
    "    pts = np.array([[lm.x, lm.y, lm.z] for lm in landmarks])\n",
    "\n",
    "    # basic reference distances\n",
    "    left_cheek = pts[FACE_LEFT_CHEEK]\n",
    "    right_cheek = pts[FACE_RIGHT_CHEEK]\n",
    "    face_width = _dist(left_cheek, right_cheek) + 1e-6\n",
    "\n",
    "    forehead = pts[10]\n",
    "    chin = pts[152]\n",
    "    face_height = _dist(forehead, chin) + 1e-6\n",
    "\n",
    "    # mouth points\n",
    "    mouth_left = pts[MOUTH_LEFT]\n",
    "    mouth_right = pts[MOUTH_RIGHT]\n",
    "    mouth_top = pts[MOUTH_TOP_INNER]\n",
    "    mouth_bottom = pts[MOUTH_BOTTOM_INNER]\n",
    "    nose_tip = pts[NOSE_TIP]\n",
    "    mouth_center = 0.5 * (mouth_left + mouth_right)\n",
    "\n",
    "    # base mouth features\n",
    "    mouth_width = _dist(mouth_left, mouth_right) / face_width\n",
    "    mouth_height = _dist(mouth_top, mouth_bottom) / face_width\n",
    "    mouth_ar = mouth_height / (mouth_width + 1e-6)\n",
    "\n",
    "    mouth_corner_asym = (mouth_left[1] - mouth_right[1])\n",
    "    mouth_center_nose_dist = _dist(mouth_center, nose_tip) / face_height\n",
    "\n",
    "    slope_left = _slope(mouth_center, mouth_left)\n",
    "    slope_right = _slope(mouth_center, mouth_right)\n",
    "    slope_mean = 0.5 * (slope_left + slope_right)\n",
    "    slope_diff = slope_left - slope_right\n",
    "\n",
    "    # extra mouth geometry\n",
    "    lip_thickness_mid = _dist(mouth_top, mouth_bottom) / face_height\n",
    "\n",
    "    mouth_corner_top_left = _dist(mouth_left, mouth_top) / face_height\n",
    "    mouth_corner_top_right = _dist(mouth_right, mouth_top) / face_height\n",
    "    mouth_corner_bottom_left = _dist(mouth_left, mouth_bottom) / face_height\n",
    "    mouth_corner_bottom_right = _dist(mouth_right, mouth_bottom) / face_height\n",
    "\n",
    "    mouth_corner_nose_left = _dist(mouth_left, nose_tip) / face_height\n",
    "    mouth_corner_nose_right = _dist(mouth_right, nose_tip) / face_height\n",
    "\n",
    "    upper_lip_curvature = _signed_point_line_distance_2d(\n",
    "        mouth_top, mouth_left, mouth_right\n",
    "    ) / (face_height + 1e-6)\n",
    "    lower_lip_curvature = _signed_point_line_distance_2d(\n",
    "        mouth_bottom, mouth_left, mouth_right\n",
    "    ) / (face_height + 1e-6)\n",
    "\n",
    "    # eyes\n",
    "    left_eye_outer = pts[LEFT_EYE_OUTER]\n",
    "    left_eye_inner = pts[LEFT_EYE_INNER]\n",
    "    left_eye_top = pts[LEFT_EYE_TOP]\n",
    "    left_eye_bottom = pts[LEFT_EYE_BOTTOM]\n",
    "\n",
    "    right_eye_outer = pts[RIGHT_EYE_OUTER]\n",
    "    right_eye_inner = pts[RIGHT_EYE_INNER]\n",
    "    right_eye_top = pts[RIGHT_EYE_TOP]\n",
    "    right_eye_bottom = pts[RIGHT_EYE_BOTTOM]\n",
    "\n",
    "    left_eye_width = _dist(left_eye_outer, left_eye_inner) / face_width\n",
    "    left_eye_height = _dist(left_eye_top, left_eye_bottom) / face_width\n",
    "\n",
    "    right_eye_width = _dist(right_eye_outer, right_eye_inner) / face_width\n",
    "    right_eye_height = _dist(right_eye_top, right_eye_bottom) / face_width\n",
    "\n",
    "    left_ear = left_eye_height / (left_eye_width + 1e-6)\n",
    "    right_ear = right_eye_height / (right_eye_width + 1e-6)\n",
    "    mean_ear = 0.5 * (left_ear + right_ear)\n",
    "    ear_diff = left_ear - right_ear\n",
    "\n",
    "    # eye centers and cheek distances\n",
    "    left_eye_center = pts[LEFT_EYE_INDICES].mean(axis=0)\n",
    "    right_eye_center = pts[RIGHT_EYE_INDICES].mean(axis=0)\n",
    "\n",
    "    left_cheek_eye = _dist(left_cheek, left_eye_center) / face_width\n",
    "    right_cheek_eye = _dist(right_cheek, right_eye_center) / face_width\n",
    "    cheek_eye_mean = 0.5 * (left_cheek_eye + right_cheek_eye)\n",
    "    cheek_eye_diff = left_cheek_eye - right_cheek_eye\n",
    "\n",
    "    # eyebrow to eye distances (existing mean based)\n",
    "    left_eye_mean_y = pts[LEFT_EYE_INDICES][:, 1].mean()\n",
    "    right_eye_mean_y = pts[RIGHT_EYE_INDICES][:, 1].mean()\n",
    "\n",
    "    left_brow_mean_y = pts[LEFT_EYEBROW_INDICES][:, 1].mean()\n",
    "    right_brow_mean_y = pts[RIGHT_EYEBROW_INDICES][:, 1].mean()\n",
    "\n",
    "    left_brow_eye = (left_brow_mean_y - left_eye_mean_y) / (face_height + 1e-6)\n",
    "    right_brow_eye = (right_brow_mean_y - right_eye_mean_y) / (face_height + 1e-6)\n",
    "    brow_eye_mean = 0.5 * (left_brow_eye + right_brow_eye)\n",
    "    brow_eye_diff = left_brow_eye - right_brow_eye\n",
    "\n",
    "    # inner vs outer brow points and richer brow geometry\n",
    "    left_inner_brow, left_outer_brow = _get_inner_outer_brow_points(\n",
    "        pts, LEFT_EYEBROW_INDICES, side=\"left\"\n",
    "    )\n",
    "    right_inner_brow, right_outer_brow = _get_inner_outer_brow_points(\n",
    "        pts, RIGHT_EYEBROW_INDICES, side=\"right\"\n",
    "    )\n",
    "\n",
    "    inner_brow_dist = _dist(left_inner_brow, right_inner_brow) / face_width\n",
    "\n",
    "    left_brow_tilt = _slope(left_inner_brow, left_outer_brow)\n",
    "    right_brow_tilt = _slope(right_inner_brow, right_outer_brow)\n",
    "    brow_tilt_diff = left_brow_tilt - right_brow_tilt\n",
    "\n",
    "    left_brow_mid = pts[LEFT_EYEBROW_INDICES].mean(axis=0)\n",
    "    right_brow_mid = pts[RIGHT_EYEBROW_INDICES].mean(axis=0)\n",
    "\n",
    "    left_brow_curv = _signed_point_line_distance_2d(\n",
    "        left_brow_mid, left_inner_brow, left_outer_brow\n",
    "    ) / (face_height + 1e-6)\n",
    "    right_brow_curv = _signed_point_line_distance_2d(\n",
    "        right_brow_mid, right_inner_brow, right_outer_brow\n",
    "    ) / (face_height + 1e-6)\n",
    "    brow_curv_mean = 0.5 * (left_brow_curv + right_brow_curv)\n",
    "    brow_curv_diff = left_brow_curv - right_brow_curv\n",
    "\n",
    "    left_inner_brow_eye = (left_inner_brow[1] - left_eye_center[1]) / (face_height + 1e-6)\n",
    "    left_outer_brow_eye = (left_outer_brow[1] - left_eye_center[1]) / (face_height + 1e-6)\n",
    "    right_inner_brow_eye = (right_inner_brow[1] - right_eye_center[1]) / (face_height + 1e-6)\n",
    "    right_outer_brow_eye = (right_outer_brow[1] - right_eye_center[1]) / (face_height + 1e-6)\n",
    "\n",
    "    inner_brow_eye_mean = 0.5 * (left_inner_brow_eye + right_inner_brow_eye)\n",
    "    outer_brow_eye_mean = 0.5 * (left_outer_brow_eye + right_outer_brow_eye)\n",
    "    inner_outer_brow_eye_diff = inner_brow_eye_mean - outer_brow_eye_mean\n",
    "\n",
    "    # global geometry\n",
    "    face_aspect = face_height / face_width\n",
    "\n",
    "    v = right_cheek - left_cheek\n",
    "    head_tilt_angle = np.arctan2(v[1], v[0])\n",
    "\n",
    "    mouth_corner_asym_norm = mouth_corner_asym / (face_height + 1e-6)\n",
    "\n",
    "    head_tilt_sin = np.sin(head_tilt_angle)\n",
    "    head_tilt_cos = np.cos(head_tilt_angle)\n",
    "\n",
    "    # build dictionary of all features so names and values stay aligned\n",
    "    feature_dict = {\n",
    "        # mouth\n",
    "        \"mouth_width\": mouth_width,\n",
    "        \"mouth_height\": mouth_height,\n",
    "        \"mouth_ar\": mouth_ar,\n",
    "        \"mouth_corner_asym_norm\": mouth_corner_asym_norm,\n",
    "        \"mouth_center_nose_dist\": mouth_center_nose_dist,\n",
    "        \"mouth_slope_left\": slope_left,\n",
    "        \"mouth_slope_right\": slope_right,\n",
    "        \"mouth_slope_mean\": slope_mean,\n",
    "        \"mouth_slope_diff\": slope_diff,\n",
    "\n",
    "        # extra mouth\n",
    "        \"lip_thickness_mid\": lip_thickness_mid,\n",
    "        \"mouth_corner_top_left\": mouth_corner_top_left,\n",
    "        \"mouth_corner_top_right\": mouth_corner_top_right,\n",
    "        \"mouth_corner_bottom_left\": mouth_corner_bottom_left,\n",
    "        \"mouth_corner_bottom_right\": mouth_corner_bottom_right,\n",
    "        \"mouth_corner_nose_left\": mouth_corner_nose_left,\n",
    "        \"mouth_corner_nose_right\": mouth_corner_nose_right,\n",
    "        \"upper_lip_curvature\": upper_lip_curvature,\n",
    "        \"lower_lip_curvature\": lower_lip_curvature,\n",
    "\n",
    "        # eyes\n",
    "        \"left_eye_width\": left_eye_width,\n",
    "        \"left_eye_height\": left_eye_height,\n",
    "        \"right_eye_width\": right_eye_width,\n",
    "        \"right_eye_height\": right_eye_height,\n",
    "        \"left_ear\": left_ear,\n",
    "        \"right_ear\": right_ear,\n",
    "        \"mean_ear\": mean_ear,\n",
    "        \"ear_diff\": ear_diff,\n",
    "\n",
    "        # eye-cheek\n",
    "        \"left_cheek_eye\": left_cheek_eye,\n",
    "        \"right_cheek_eye\": right_cheek_eye,\n",
    "        \"cheek_eye_mean\": cheek_eye_mean,\n",
    "        \"cheek_eye_diff\": cheek_eye_diff,\n",
    "\n",
    "        # brows\n",
    "        \"left_brow_eye\": left_brow_eye,\n",
    "        \"right_brow_eye\": right_brow_eye,\n",
    "        \"brow_eye_mean\": brow_eye_mean,\n",
    "        \"brow_eye_diff\": brow_eye_diff,\n",
    "\n",
    "        # brow geometry\n",
    "        \"inner_brow_dist\": inner_brow_dist,\n",
    "        \"left_brow_tilt\": left_brow_tilt,\n",
    "        \"right_brow_tilt\": right_brow_tilt,\n",
    "        \"brow_tilt_diff\": brow_tilt_diff,\n",
    "        \"left_brow_curv\": left_brow_curv,\n",
    "        \"right_brow_curv\": right_brow_curv,\n",
    "        \"brow_curv_mean\": brow_curv_mean,\n",
    "        \"brow_curv_diff\": brow_curv_diff,\n",
    "        \"left_inner_brow_eye\": left_inner_brow_eye,\n",
    "        \"left_outer_brow_eye\": left_outer_brow_eye,\n",
    "        \"right_inner_brow_eye\": right_inner_brow_eye,\n",
    "        \"right_outer_brow_eye\": right_outer_brow_eye,\n",
    "        \"inner_brow_eye_mean\": inner_brow_eye_mean,\n",
    "        \"outer_brow_eye_mean\": outer_brow_eye_mean,\n",
    "        \"inner_outer_brow_eye_diff\": inner_outer_brow_eye_diff,\n",
    "\n",
    "        # global\n",
    "        \"face_aspect\": face_aspect,\n",
    "        \"head_tilt_angle\": head_tilt_angle,\n",
    "        \"head_tilt_sin\": head_tilt_sin,\n",
    "        \"head_tilt_cos\": head_tilt_cos,\n",
    "    }\n",
    "\n",
    "    features, feature_names = make_feature_array(feature_dict)\n",
    "    return features, feature_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "722a0bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_dataset_paths():\n",
    "    path = kagglehub.dataset_download(\"jonathanoheix/face-expression-recognition-dataset\")\n",
    "    train_dir = os.path.join(path, \"images\", \"train\")\n",
    "    val_dir = os.path.join(path, \"images\", \"validation\")\n",
    "    return train_dir, val_dir\n",
    "\n",
    "def iterate_images(root_dir):\n",
    "    class_names = sorted([\n",
    "        d for d in os.listdir(root_dir)\n",
    "        if os.path.isdir(os.path.join(root_dir, d))\n",
    "    ])\n",
    "\n",
    "    for label in class_names:\n",
    "        class_dir = os.path.join(root_dir, label)\n",
    "        for fname in os.listdir(class_dir):\n",
    "            if not fname.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                continue\n",
    "            full_path = os.path.join(class_dir, fname)\n",
    "            yield full_path, label\n",
    "\n",
    "\n",
    "def preprocess_to_csv(root_dir, output_csv, img_size=48):\n",
    "    face_mesh = mp_face_mesh.FaceMesh(\n",
    "        static_image_mode=True,\n",
    "        max_num_faces=1,\n",
    "        refine_landmarks=True,\n",
    "        min_detection_confidence=0.5,\n",
    "    )\n",
    "\n",
    "    rows = []\n",
    "    count = 0\n",
    "\n",
    "    for img_path, label in iterate_images(root_dir):\n",
    "        img_gray = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img_gray is None:\n",
    "            continue\n",
    "\n",
    "        img_gray = cv2.resize(img_gray, (img_size, img_size))\n",
    "        img_rgb = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "        result = face_mesh.process(img_rgb)\n",
    "        if not result.multi_face_landmarks:\n",
    "            continue\n",
    "\n",
    "        landmarks = result.multi_face_landmarks[0].landmark\n",
    "        feat_values, feat_names = extract_features(landmarks)\n",
    "        rows.append(feat_values.tolist() + [label])\n",
    "        count += 1\n",
    "\n",
    "        if count % 500 == 0:\n",
    "            print(f\"Processed {count} images from {root_dir}...\")\n",
    "\n",
    "    if not rows:\n",
    "        print(f\"No rows collected for {root_dir}, nothing to write.\")\n",
    "        return\n",
    "\n",
    "    num_features = len(rows[0]) - 1\n",
    "    header = [f\"f{i}\" for i in range(num_features)] + [\"label\"]\n",
    "\n",
    "    print(f\"Writing {len(rows)} rows to {output_csv}\")\n",
    "    with open(output_csv, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(header)\n",
    "        writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ddc0f76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1764793872.003796 3995129 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 88.1), renderer: Apple M1\n",
      "W0000 00:00:1764793872.031974 4020751 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1764793872.040614 4020751 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 500 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 1000 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 1500 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 2000 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 2500 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 3000 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 3500 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 4000 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 4500 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 5000 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 5500 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 6000 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 6500 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 7000 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 7500 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 8000 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 8500 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 9000 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 9500 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 10000 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 10500 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 11000 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 11500 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 12000 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 12500 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 13000 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 13500 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 14000 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 14500 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 15000 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 15500 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 16000 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 16500 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 17000 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 17500 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 18000 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 18500 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 19000 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 19500 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 20000 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 20500 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 21000 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 21500 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 22000 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 22500 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 23000 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 23500 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 24000 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 24500 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 25000 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 25500 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 26000 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Processed 26500 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/train...\n",
      "Writing 26784 rows to ../data/train_features.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1764794005.689356 3995129 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 88.1), renderer: Apple M1\n",
      "W0000 00:00:1764794005.691738 4022695 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1764794005.701582 4022694 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 500 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/validation...\n",
      "Processed 1000 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/validation...\n",
      "Processed 1500 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/validation...\n",
      "Processed 2000 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/validation...\n",
      "Processed 2500 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/validation...\n",
      "Processed 3000 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/validation...\n",
      "Processed 3500 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/validation...\n",
      "Processed 4000 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/validation...\n",
      "Processed 4500 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/validation...\n",
      "Processed 5000 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/validation...\n",
      "Processed 5500 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/validation...\n",
      "Processed 6000 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/validation...\n",
      "Processed 6500 images from /Users/nav/.cache/kagglehub/datasets/jonathanoheix/face-expression-recognition-dataset/versions/1/images/validation...\n",
      "Writing 6599 rows to ../data/val_features.csv\n"
     ]
    }
   ],
   "source": [
    "train_dir, val_dir = get_dataset_paths()\n",
    "preprocess_to_csv(train_dir, \"../data/train_features.csv\")\n",
    "preprocess_to_csv(val_dir, \"../data/val_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ecdff1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"../data/train_features.csv\")\n",
    "val_df = pd.read_csv(\"../data/val_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43b89e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10',\n",
       "       'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20',\n",
       "       'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30',\n",
       "       'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40',\n",
       "       'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50',\n",
       "       'f51', 'f52', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "25b3cfe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "happy       6899\n",
       "neutral     4819\n",
       "sad         4409\n",
       "fear        3699\n",
       "angry       3544\n",
       "surprise    3036\n",
       "disgust      378\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d71647a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f44</th>\n",
       "      <th>f45</th>\n",
       "      <th>f46</th>\n",
       "      <th>f47</th>\n",
       "      <th>f48</th>\n",
       "      <th>f49</th>\n",
       "      <th>f50</th>\n",
       "      <th>f51</th>\n",
       "      <th>f52</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3544</th>\n",
       "      <td>0.413178</td>\n",
       "      <td>0.192618</td>\n",
       "      <td>0.466185</td>\n",
       "      <td>-0.057908</td>\n",
       "      <td>0.333224</td>\n",
       "      <td>0.164280</td>\n",
       "      <td>0.164278</td>\n",
       "      <td>0.164279</td>\n",
       "      <td>2.021374e-06</td>\n",
       "      <td>0.166698</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081379</td>\n",
       "      <td>-0.113389</td>\n",
       "      <td>-0.110012</td>\n",
       "      <td>-0.102167</td>\n",
       "      <td>-0.007845</td>\n",
       "      <td>1.155492</td>\n",
       "      <td>0.148629</td>\n",
       "      <td>0.148082</td>\n",
       "      <td>0.988975</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3545</th>\n",
       "      <td>0.366580</td>\n",
       "      <td>0.002975</td>\n",
       "      <td>0.008116</td>\n",
       "      <td>-0.005619</td>\n",
       "      <td>0.274076</td>\n",
       "      <td>0.018910</td>\n",
       "      <td>0.018910</td>\n",
       "      <td>0.018910</td>\n",
       "      <td>2.628474e-07</td>\n",
       "      <td>0.002523</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077340</td>\n",
       "      <td>-0.085596</td>\n",
       "      <td>-0.093987</td>\n",
       "      <td>-0.114699</td>\n",
       "      <td>0.020711</td>\n",
       "      <td>1.179423</td>\n",
       "      <td>-0.123804</td>\n",
       "      <td>-0.123488</td>\n",
       "      <td>0.992346</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3546</th>\n",
       "      <td>0.368501</td>\n",
       "      <td>0.018032</td>\n",
       "      <td>0.048933</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.268026</td>\n",
       "      <td>-0.000843</td>\n",
       "      <td>-0.000843</td>\n",
       "      <td>-0.000843</td>\n",
       "      <td>-1.107547e-08</td>\n",
       "      <td>0.014907</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069749</td>\n",
       "      <td>-0.115339</td>\n",
       "      <td>-0.048201</td>\n",
       "      <td>-0.096928</td>\n",
       "      <td>0.048727</td>\n",
       "      <td>1.209658</td>\n",
       "      <td>-0.038514</td>\n",
       "      <td>-0.038504</td>\n",
       "      <td>0.999258</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3547</th>\n",
       "      <td>0.352277</td>\n",
       "      <td>0.082331</td>\n",
       "      <td>0.233710</td>\n",
       "      <td>0.023231</td>\n",
       "      <td>0.277251</td>\n",
       "      <td>-0.084161</td>\n",
       "      <td>-0.084159</td>\n",
       "      <td>-0.084160</td>\n",
       "      <td>-1.246755e-06</td>\n",
       "      <td>0.065754</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.065032</td>\n",
       "      <td>-0.082568</td>\n",
       "      <td>-0.076105</td>\n",
       "      <td>-0.093348</td>\n",
       "      <td>0.017243</td>\n",
       "      <td>1.252114</td>\n",
       "      <td>-0.079918</td>\n",
       "      <td>-0.079833</td>\n",
       "      <td>0.996808</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3548</th>\n",
       "      <td>0.347480</td>\n",
       "      <td>0.075914</td>\n",
       "      <td>0.218471</td>\n",
       "      <td>0.049908</td>\n",
       "      <td>0.283811</td>\n",
       "      <td>-0.179168</td>\n",
       "      <td>-0.179166</td>\n",
       "      <td>-0.179167</td>\n",
       "      <td>-2.543680e-06</td>\n",
       "      <td>0.065991</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051039</td>\n",
       "      <td>-0.051194</td>\n",
       "      <td>-0.048692</td>\n",
       "      <td>-0.091440</td>\n",
       "      <td>0.042748</td>\n",
       "      <td>1.150373</td>\n",
       "      <td>-0.201656</td>\n",
       "      <td>-0.200292</td>\n",
       "      <td>0.979736</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3917</th>\n",
       "      <td>0.450030</td>\n",
       "      <td>0.134156</td>\n",
       "      <td>0.298103</td>\n",
       "      <td>-0.017895</td>\n",
       "      <td>0.296697</td>\n",
       "      <td>0.054205</td>\n",
       "      <td>0.054205</td>\n",
       "      <td>0.054205</td>\n",
       "      <td>5.784295e-07</td>\n",
       "      <td>0.100676</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026495</td>\n",
       "      <td>-0.088694</td>\n",
       "      <td>-0.035168</td>\n",
       "      <td>-0.085296</td>\n",
       "      <td>0.050128</td>\n",
       "      <td>1.332551</td>\n",
       "      <td>0.028317</td>\n",
       "      <td>0.028314</td>\n",
       "      <td>0.999599</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3918</th>\n",
       "      <td>0.450030</td>\n",
       "      <td>0.134156</td>\n",
       "      <td>0.298103</td>\n",
       "      <td>-0.017895</td>\n",
       "      <td>0.296697</td>\n",
       "      <td>0.054205</td>\n",
       "      <td>0.054205</td>\n",
       "      <td>0.054205</td>\n",
       "      <td>5.784295e-07</td>\n",
       "      <td>0.100676</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026495</td>\n",
       "      <td>-0.088694</td>\n",
       "      <td>-0.035168</td>\n",
       "      <td>-0.085296</td>\n",
       "      <td>0.050128</td>\n",
       "      <td>1.332551</td>\n",
       "      <td>0.028317</td>\n",
       "      <td>0.028314</td>\n",
       "      <td>0.999599</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3919</th>\n",
       "      <td>0.284852</td>\n",
       "      <td>0.016211</td>\n",
       "      <td>0.056910</td>\n",
       "      <td>-0.001232</td>\n",
       "      <td>0.307201</td>\n",
       "      <td>0.004811</td>\n",
       "      <td>0.004811</td>\n",
       "      <td>0.004811</td>\n",
       "      <td>7.919468e-08</td>\n",
       "      <td>0.015061</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050437</td>\n",
       "      <td>-0.098121</td>\n",
       "      <td>-0.062644</td>\n",
       "      <td>-0.098423</td>\n",
       "      <td>0.035779</td>\n",
       "      <td>1.076356</td>\n",
       "      <td>0.012680</td>\n",
       "      <td>0.012680</td>\n",
       "      <td>0.999920</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3920</th>\n",
       "      <td>0.419064</td>\n",
       "      <td>0.104245</td>\n",
       "      <td>0.248757</td>\n",
       "      <td>-0.018916</td>\n",
       "      <td>0.307016</td>\n",
       "      <td>0.053849</td>\n",
       "      <td>0.053848</td>\n",
       "      <td>0.053848</td>\n",
       "      <td>5.752945e-07</td>\n",
       "      <td>0.088586</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054124</td>\n",
       "      <td>-0.080700</td>\n",
       "      <td>-0.042427</td>\n",
       "      <td>-0.085764</td>\n",
       "      <td>0.043337</td>\n",
       "      <td>1.176775</td>\n",
       "      <td>-0.009330</td>\n",
       "      <td>-0.009330</td>\n",
       "      <td>0.999956</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3921</th>\n",
       "      <td>0.324195</td>\n",
       "      <td>0.008361</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.308482</td>\n",
       "      <td>-0.002695</td>\n",
       "      <td>-0.002695</td>\n",
       "      <td>-0.002695</td>\n",
       "      <td>-4.661496e-08</td>\n",
       "      <td>0.007182</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058564</td>\n",
       "      <td>-0.077852</td>\n",
       "      <td>-0.052336</td>\n",
       "      <td>-0.070691</td>\n",
       "      <td>0.018355</td>\n",
       "      <td>1.164197</td>\n",
       "      <td>-0.043319</td>\n",
       "      <td>-0.043306</td>\n",
       "      <td>0.999062</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>378 rows Ã— 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            f0        f1        f2        f3        f4        f5        f6  \\\n",
       "3544  0.413178  0.192618  0.466185 -0.057908  0.333224  0.164280  0.164278   \n",
       "3545  0.366580  0.002975  0.008116 -0.005619  0.274076  0.018910  0.018910   \n",
       "3546  0.368501  0.018032  0.048933  0.000255  0.268026 -0.000843 -0.000843   \n",
       "3547  0.352277  0.082331  0.233710  0.023231  0.277251 -0.084161 -0.084159   \n",
       "3548  0.347480  0.075914  0.218471  0.049908  0.283811 -0.179168 -0.179166   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3917  0.450030  0.134156  0.298103 -0.017895  0.296697  0.054205  0.054205   \n",
       "3918  0.450030  0.134156  0.298103 -0.017895  0.296697  0.054205  0.054205   \n",
       "3919  0.284852  0.016211  0.056910 -0.001232  0.307201  0.004811  0.004811   \n",
       "3920  0.419064  0.104245  0.248757 -0.018916  0.307016  0.053849  0.053848   \n",
       "3921  0.324195  0.008361  0.025791  0.000654  0.308482 -0.002695 -0.002695   \n",
       "\n",
       "            f7            f8        f9  ...       f44       f45       f46  \\\n",
       "3544  0.164279  2.021374e-06  0.166698  ... -0.081379 -0.113389 -0.110012   \n",
       "3545  0.018910  2.628474e-07  0.002523  ... -0.077340 -0.085596 -0.093987   \n",
       "3546 -0.000843 -1.107547e-08  0.014907  ... -0.069749 -0.115339 -0.048201   \n",
       "3547 -0.084160 -1.246755e-06  0.065754  ... -0.065032 -0.082568 -0.076105   \n",
       "3548 -0.179167 -2.543680e-06  0.065991  ... -0.051039 -0.051194 -0.048692   \n",
       "...        ...           ...       ...  ...       ...       ...       ...   \n",
       "3917  0.054205  5.784295e-07  0.100676  ... -0.026495 -0.088694 -0.035168   \n",
       "3918  0.054205  5.784295e-07  0.100676  ... -0.026495 -0.088694 -0.035168   \n",
       "3919  0.004811  7.919468e-08  0.015061  ... -0.050437 -0.098121 -0.062644   \n",
       "3920  0.053848  5.752945e-07  0.088586  ... -0.054124 -0.080700 -0.042427   \n",
       "3921 -0.002695 -4.661496e-08  0.007182  ... -0.058564 -0.077852 -0.052336   \n",
       "\n",
       "           f47       f48       f49       f50       f51       f52    label  \n",
       "3544 -0.102167 -0.007845  1.155492  0.148629  0.148082  0.988975  disgust  \n",
       "3545 -0.114699  0.020711  1.179423 -0.123804 -0.123488  0.992346  disgust  \n",
       "3546 -0.096928  0.048727  1.209658 -0.038514 -0.038504  0.999258  disgust  \n",
       "3547 -0.093348  0.017243  1.252114 -0.079918 -0.079833  0.996808  disgust  \n",
       "3548 -0.091440  0.042748  1.150373 -0.201656 -0.200292  0.979736  disgust  \n",
       "...        ...       ...       ...       ...       ...       ...      ...  \n",
       "3917 -0.085296  0.050128  1.332551  0.028317  0.028314  0.999599  disgust  \n",
       "3918 -0.085296  0.050128  1.332551  0.028317  0.028314  0.999599  disgust  \n",
       "3919 -0.098423  0.035779  1.076356  0.012680  0.012680  0.999920  disgust  \n",
       "3920 -0.085764  0.043337  1.176775 -0.009330 -0.009330  0.999956  disgust  \n",
       "3921 -0.070691  0.018355  1.164197 -0.043319 -0.043306  0.999062  disgust  \n",
       "\n",
       "[378 rows x 54 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df[\"label\"] == \"disgust\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae4d510",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72249fa1-cb2d-4725-84e3-39e689e62bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
